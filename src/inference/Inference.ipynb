{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix for GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U --no-cache-dir gdown --pre > /dev/null\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown \"1Hkn-xh9gqjWOCkFA0OwzvWPDRsIPwdSv\"\n",
    "# !unzip -o \"AAA_DATASET_v7.zip\" > /dev/null"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = \"Curvature_2_ECAP\"\n",
    "\n",
    "MODEL_NAME = \"MultiViewUNet_Curvature_2_TAWSS_2_ECAP\"\n",
    "DATASET_DIR = \"/content/Images/\"\n",
    "TRAIN_DIR = \"Train/\"\n",
    "TEST_DIR = \"Test/\"\n",
    "INPUT_DIR = PROBLEM.split(\"_2_\")[0]\n",
    "TARGET_DIR = PROBLEM.split(\"_2_\")[1]\n",
    "PRED_DIR = \"/content/drive/MyDrive/Research/TAVI/Predictions/\"\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "VAL_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 300\n",
    "PATIENCE = 30\n",
    "\n",
    "MODEL_PATH = \"\"\n",
    "SECOND_MODEL_PATH = \"\"\n",
    "\n",
    "EXP_NAME = f\"{MODEL_NAME}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_dir(path: str) -> tf.data.Dataset:\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=path,\n",
    "        labels=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        interpolation='bilinear',\n",
    "        follow_links=False,\n",
    "        crop_to_aspect_ratio=False\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = load_data_from_dir(os.path.join(DATASET_DIR, TRAIN_DIR, INPUT_DIR))\n",
    "trainY = load_data_from_dir(os.path.join(DATASET_DIR, TRAIN_DIR, TARGET_DIR))\n",
    "testX = load_data_from_dir(os.path.join(DATASET_DIR, TEST_DIR, INPUT_DIR))\n",
    "testY = load_data_from_dir(os.path.join(DATASET_DIR, TEST_DIR, TARGET_DIR))\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((trainX, trainY))\n",
    "test_ds = tf.data.Dataset.zip((testX, testY))\n",
    "\n",
    "print(train_ds.element_spec)\n",
    "print(test_ds.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (\n",
    "    normalization_layer(x), normalization_layer(y)))\n",
    "test_ds = test_ds.map(lambda x, y: (\n",
    "    normalization_layer(x), normalization_layer(y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_batches = (\n",
    "    train_ds\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_batches = (\n",
    "    test_ds\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions / Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_mse(y_true, y_pred):\n",
    "    _y_true = y_true[y_true != 1.0]\n",
    "    _y_pred = y_pred[y_true != 1.0]\n",
    "    squared_difference = tf.square(_y_true - _y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "\n",
    "def attention_mae(y_true, y_pred):\n",
    "    _y_true = y_true[y_true != 1.0]\n",
    "    _y_pred = y_pred[y_true != 1.0]\n",
    "    squared_difference = tf.abs(_y_true - _y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={\"attention_mse\": attention_mse}\n",
    ")\n",
    "second_model = tf.keras.models.load_model(\n",
    "    SECOND_MODEL_PATH,\n",
    "    custom_objects={\"attention_mse\": attention_mse}\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_ds)\n",
    "second_prediction = second_model.predict(prediction)\n",
    "\n",
    "for idx, image in enumerate(second_prediction.unbatch()):\n",
    "    print(image.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
